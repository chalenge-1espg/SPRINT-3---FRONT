import os
import google.generativeai as genai
from flask import Flask, request, jsonify
from flask_cors import CORS

# Configure a chave da API
genai.configure(api_key="AIzaSyCMcoxStrIOvx1beAWCRzGF84hRbc-Gmjw")

# Escolhe o modelo
model = genai.GenerativeModel("gemini-2.5-flash")
# Lista para armazenar o histÃ³rico da conversa
historico = []

# DicionÃ¡rio para salvar informaÃ§Ãµes rÃ¡pidas (exemplo local, sem chamar API)
faq = {
    "quando comecou": "O futebol feminino no Brasil comeÃ§ou oficialmente em 1983, apÃ³s o fim da proibiÃ§Ã£o.",
    "primeira copa": "A primeira Copa do Mundo de Futebol Feminino foi realizada em 1991, na China.",
    "seleÃ§Ã£o brasileira": "A seleÃ§Ã£o brasileira feminina Ã© uma das mais fortes do mundo, revelando craques como Marta."
}

# FunÃ§Ã£o para chamar o modelo Gemini
def consultar_gemini(pergunta: str) -> str:
    response = model.generate_content(
        f"VocÃª Ã© um especialista em futebol feminino. Responda de forma sucinta clara e objetiva: {pergunta}"
    )
    return response.text

# -----------------------------
# ğŸš€ ADIÃ‡ÃƒO: Servidor Flask
# -----------------------------
app = Flask(__name__)
CORS(app)

@app.route("/chat", methods=["POST"])
def chat():
    data = request.json
    pergunta = data.get("message", "").strip().lower()

    if not pergunta:
        return jsonify({"response": "âš ï¸ Nenhuma mensagem recebida."})

    # Se estiver no FAQ, responde direto
    if pergunta in faq:
        resposta = faq[pergunta]
    else:
        resposta = consultar_gemini(pergunta)

    # Salva no histÃ³rico
    historico.append({"usuario": pergunta, "bot": resposta})

    return jsonify({"response": resposta})

if __name__ == "__main__":
    # Inicia o Flask
    app.run(port=5000, debug=True)
    